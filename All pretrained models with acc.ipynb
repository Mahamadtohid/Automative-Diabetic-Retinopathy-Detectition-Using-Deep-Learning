{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":629378,"sourceType":"datasetVersion","datasetId":309764}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# FIXED SOLUTION: Exclude nested aptos-augmented-images folder\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.applications import ResNet50, ResNet152, DenseNet121\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import classification_report, confusion_matrix, precision_score\nfrom sklearn.utils.class_weight import compute_class_weight\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nimport shutil\n\n# Set random seeds\nnp.random.seed(42)\ntf.random.set_seed(42)\n\n# Configuration\nIMG_HEIGHT, IMG_WIDTH = 224, 224\nBATCH_SIZE = 32\nNUM_CLASSES = 5\nEPOCHS = 30\n\n# Dataset path - go directly to the inner directory with class folders\npath = \"/kaggle/input/aptos-augmented-images\"\nactual_path = os.path.join(path, \"aptos-augmented-images\")\n\nprint(\"STEP 1: Fixing dataset structure...\")\nprint(f\"Using directory: {actual_path}\")\n\n# Create a clean directory structure excluding the nested folder\nclean_path = \"/tmp/clean_aptos\"\nif os.path.exists(clean_path):\n    shutil.rmtree(clean_path)\nos.makedirs(clean_path, exist_ok=True)\n\nprint(\"\\nSTEP 2: Creating clean class structure...\")\n# Copy only the 5 diabetic retinopathy class folders (0, 1, 2, 3, 4)\nclass_names = ['0', '1', '2', '3', '4']\ntotal_images = 0\n\nfor class_name in class_names:\n    src_class_path = os.path.join(actual_path, class_name)\n    dst_class_path = os.path.join(clean_path, class_name)\n    \n    if os.path.exists(src_class_path) and os.path.isdir(src_class_path):\n        # Create destination class directory\n        os.makedirs(dst_class_path, exist_ok=True)\n        \n        # Copy all images from source to destination\n        images = [f for f in os.listdir(src_class_path) \n                 if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n        \n        for img in images:\n            src_img = os.path.join(src_class_path, img)\n            dst_img = os.path.join(dst_class_path, img)\n            shutil.copy2(src_img, dst_img)\n        \n        print(f\"  âœ… Class {class_name}: {len(images)} images copied\")\n        total_images += len(images)\n    else:\n        print(f\"  âŒ Class {class_name}: folder not found\")\n\nprint(f\"\\nTotal images processed: {total_images}\")\nprint(\"Excluded: aptos-augmented-images nested folder\")\n\n# Verify clean structure\nprint(\"\\nSTEP 3: Verifying clean structure...\")\nfor class_name in class_names:\n    class_path = os.path.join(clean_path, class_name)\n    if os.path.exists(class_path):\n        count = len(os.listdir(class_path))\n        print(f\"  Class {class_name}: {count} images\")\n\n# Create data generators using the clean structure\nprint(\"\\nSTEP 4: Creating data generators...\")\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,\n    zoom_range=0.2,\n    shear_range=0.2,\n    fill_mode='nearest',\n    validation_split=0.2\n)\n\ntrain_generator = train_datagen.flow_from_directory(\n    clean_path,  # Use clean path without nested folder\n    target_size=(IMG_HEIGHT, IMG_WIDTH),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True\n)\n\nvalidation_generator = train_datagen.flow_from_directory(\n    clean_path,  # Use clean path without nested folder\n    target_size=(IMG_HEIGHT, IMG_WIDTH),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False\n)\n\n# Verify the fix\nprint(\"\\nSTEP 5: Verification Results...\")\nprint(f\"Train: {train_generator.samples} images, {train_generator.num_classes} classes\")\nprint(f\"Validation: {validation_generator.samples} images, {validation_generator.num_classes} classes\")\nprint(f\"Class indices: {train_generator.class_indices}\")\n\n# Test batch shapes\nx_batch, y_batch = next(train_generator)\nprint(f\"\\nBatch shapes:\")\nprint(f\"Input: {x_batch.shape}\")\nprint(f\"Labels: {y_batch.shape}\")\n\nif y_batch.shape[1] == NUM_CLASSES and train_generator.num_classes == NUM_CLASSES:\n    print(\"\\nâœ… SUCCESS: Perfect! 5 classes with correct label shape!\")\n    print(\"âœ… Ready for categorical_crossentropy loss function\")\n    use_categorical = True\nelse:\n    print(\"\\nâŒ Still have issues with class count\")\n    use_categorical = False\n\n# Calculate class weights for balanced training\nclass_labels = train_generator.classes\nunique_classes = np.unique(class_labels)\nclass_weights = compute_class_weight('balanced', classes=unique_classes, y=class_labels)\nclass_weight_dict = dict(zip(unique_classes, class_weights))\n\nprint(f\"\\nClass distribution in training:\")\nfor class_idx in range(NUM_CLASSES):\n    count = np.sum(class_labels == class_idx)\n    print(f\"  Class {class_idx}: {count} samples\")\n\nprint(f\"\\nClass weights: {class_weight_dict}\")\n\n# Setup callbacks\nearly_stopping = EarlyStopping(patience=10, restore_best_weights=True)\nreduce_lr = ReduceLROnPlateau(factor=0.2, patience=5, min_lr=0.0001)\n\nprint(\"\\nğŸ¯ DATASET READY FOR MODEL TRAINING!\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-15T12:59:37.774856Z","iopub.execute_input":"2025-09-15T12:59:37.775050Z","iopub.status.idle":"2025-09-15T13:01:54.659163Z","shell.execute_reply.started":"2025-09-15T12:59:37.775032Z","shell.execute_reply":"2025-09-15T13:01:54.658363Z"}},"outputs":[{"name":"stderr","text":"2025-09-15 12:59:40.341234: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1757941180.549741      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1757941180.613265      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"STEP 1: Fixing dataset structure...\nUsing directory: /kaggle/input/aptos-augmented-images/aptos-augmented-images\n\nSTEP 2: Creating clean class structure...\n  âœ… Class 0: 2000 images copied\n  âœ… Class 1: 2000 images copied\n  âœ… Class 2: 2000 images copied\n  âœ… Class 3: 2000 images copied\n  âœ… Class 4: 2000 images copied\n\nTotal images processed: 10000\nExcluded: aptos-augmented-images nested folder\n\nSTEP 3: Verifying clean structure...\n  Class 0: 2000 images\n  Class 1: 2000 images\n  Class 2: 2000 images\n  Class 3: 2000 images\n  Class 4: 2000 images\n\nSTEP 4: Creating data generators...\nFound 8000 images belonging to 5 classes.\nFound 2000 images belonging to 5 classes.\n\nSTEP 5: Verification Results...\nTrain: 8000 images, 5 classes\nValidation: 2000 images, 5 classes\nClass indices: {'0': 0, '1': 1, '2': 2, '3': 3, '4': 4}\n\nBatch shapes:\nInput: (32, 224, 224, 3)\nLabels: (32, 5)\n\nâœ… SUCCESS: Perfect! 5 classes with correct label shape!\nâœ… Ready for categorical_crossentropy loss function\n\nClass distribution in training:\n  Class 0: 1600 samples\n  Class 1: 1600 samples\n  Class 2: 1600 samples\n  Class 3: 1600 samples\n  Class 4: 1600 samples\n\nClass weights: {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0}\n\nğŸ¯ DATASET READY FOR MODEL TRAINING!\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# CELL 1: ResNet50 Direct Implementation\nprint(\"=\"*60)\nprint(\"RESNET50 MODEL ON APTOS DATASET\")\nprint(\"=\"*60)\n\n# Load ResNet50 pretrained model\nresnet50_base = ResNet50(\n    weights='imagenet',\n    include_top=False,  # Remove final classification layer\n    input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n)\n\n# Freeze the base model\nresnet50_base.trainable = False\n\n# Add custom classification head\nresnet50_model = keras.Sequential([\n    resnet50_base,\n    keras.layers.GlobalAveragePooling2D(),\n    keras.layers.Dropout(0.2),\n    keras.layers.Dense(NUM_CLASSES, activation='softmax')\n], name='ResNet50_APTOS')\n\n# Compile model\nresnet50_model.compile(\n    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n    loss='categorical_crossentropy',\n    metrics=['accuracy', 'precision', 'recall']\n)\n\nprint(f\"ResNet50 Model: {resnet50_model.count_params():,} parameters\")\nprint(\"Base model frozen, training classification head only\")\n\n# Train ResNet50\nprint(\"\\nTraining ResNet50...\")\nresnet50_history = resnet50_model.fit(\n    train_generator,\n    epochs=EPOCHS,\n    validation_data=validation_generator,\n    class_weight=class_weight_dict,\n    callbacks=[early_stopping, reduce_lr],\n    verbose=1\n)\n\n# Fine-tune ResNet50\nprint(\"\\nFine-tuning ResNet50 (unfreezing base model)...\")\nresnet50_base.trainable = True\nresnet50_model.compile(\n    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n    loss='categorical_crossentropy',\n    metrics=['accuracy', 'precision', 'recall']\n)\n\nresnet50_history_fine = resnet50_model.fit(\n    train_generator,\n    epochs=20,\n    validation_data=validation_generator,\n    class_weight=class_weight_dict,\n    callbacks=[early_stopping, reduce_lr],\n    verbose=1\n)\n\n# Get predictions and precision matrix\nresnet50_predictions = resnet50_model.predict(validation_generator)\nresnet50_pred_classes = np.argmax(resnet50_predictions, axis=1)\n\n# Get true classes\nresnet50_true_classes = []\nvalidation_generator.reset()\nfor i in range(len(validation_generator)):\n    _, y_batch = validation_generator[i]\n    resnet50_true_classes.extend(np.argmax(y_batch, axis=1))\n\n# Precision matrix (confusion matrix)\nresnet50_cm = confusion_matrix(resnet50_true_classes, resnet50_pred_classes)\nresnet50_precision = precision_score(resnet50_true_classes, resnet50_pred_classes, average=None, zero_division=0)\n\nprint(\"\\nResNet50 Results:\")\nprint(\"Precision Matrix (Confusion Matrix):\")\nprint(resnet50_cm)\nprint(f\"Class-wise Precision: {resnet50_precision}\")\nprint(f\"Mean Precision: {np.mean(resnet50_precision):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T17:39:56.003510Z","iopub.execute_input":"2025-09-14T17:39:56.003792Z","iopub.status.idle":"2025-09-14T19:41:07.194596Z","shell.execute_reply.started":"2025-09-14T17:39:56.003772Z","shell.execute_reply":"2025-09-14T19:41:07.193717Z"}},"outputs":[{"name":"stdout","text":"============================================================\nRESNET50 MODEL ON APTOS DATASET\n============================================================\nResNet50 Model: 23,597,957 parameters\nBase model frozen, training classification head only\n\nTraining ResNet50...\nEpoch 1/50\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 498ms/step - accuracy: 0.2654 - loss: 1.5983 - precision: 0.6665 - recall: 0.0222 - val_accuracy: 0.3380 - val_loss: 1.4219 - val_precision: 0.8550 - val_recall: 0.0855 - learning_rate: 0.0010\nEpoch 2/50\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 473ms/step - accuracy: 0.3950 - loss: 1.3925 - precision: 0.8556 - recall: 0.1023 - val_accuracy: 0.3130 - val_loss: 1.4006 - val_precision: 0.7283 - val_recall: 0.1260 - learning_rate: 0.0010\nEpoch 3/50\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 469ms/step - accuracy: 0.4036 - loss: 1.3596 - precision: 0.8053 - recall: 0.1322 - val_accuracy: 0.4225 - val_loss: 1.3555 - val_precision: 0.7943 - val_recall: 0.1255 - learning_rate: 0.0010\nEpoch 4/50\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 469ms/step - accuracy: 0.4205 - loss: 1.3321 - precision: 0.8021 - recall: 0.1432 - val_accuracy: 0.4200 - val_loss: 1.3389 - val_precision: 0.7844 - val_recall: 0.1310 - learning_rate: 0.0010\nEpoch 5/50\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 468ms/step - accuracy: 0.4161 - loss: 1.3224 - precision: 0.8014 - recall: 0.1538 - val_accuracy: 0.4065 - val_loss: 1.3529 - val_precision: 0.7629 - val_recall: 0.1335 - learning_rate: 0.0010\nEpoch 6/50\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 488ms/step - accuracy: 0.4309 - loss: 1.3163 - precision: 0.7882 - recall: 0.1570 - val_accuracy: 0.4315 - val_loss: 1.3244 - val_precision: 0.7317 - val_recall: 0.1350 - learning_rate: 0.0010\nEpoch 7/50\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 483ms/step - accuracy: 0.4242 - loss: 1.3100 - precision: 0.7692 - recall: 0.1565 - val_accuracy: 0.4050 - val_loss: 1.3195 - val_precision: 0.7704 - val_recall: 0.1460 - learning_rate: 0.0010\nEpoch 8/50\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 475ms/step - accuracy: 0.4274 - loss: 1.3050 - precision: 0.7795 - recall: 0.1635 - val_accuracy: 0.4325 - val_loss: 1.3162 - val_precision: 0.7675 - val_recall: 0.1535 - learning_rate: 0.0010\nEpoch 9/50\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 475ms/step - accuracy: 0.4339 - loss: 1.3012 - precision: 0.7626 - recall: 0.1604 - val_accuracy: 0.4460 - val_loss: 1.3017 - val_precision: 0.7714 - val_recall: 0.1485 - learning_rate: 0.0010\nEpoch 10/50\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 477ms/step - accuracy: 0.4326 - loss: 1.3073 - precision: 0.7640 - recall: 0.1643 - val_accuracy: 0.4175 - val_loss: 1.3260 - val_precision: 0.7347 - val_recall: 0.1440 - learning_rate: 0.0010\nEpoch 11/50\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 483ms/step - accuracy: 0.4359 - loss: 1.2919 - precision: 0.7650 - recall: 0.1778 - val_accuracy: 0.4435 - val_loss: 1.2870 - val_precision: 0.8113 - val_recall: 0.1505 - learning_rate: 0.0010\nEpoch 12/50\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 476ms/step - accuracy: 0.4485 - loss: 1.2850 - precision: 0.7950 - recall: 0.1697 - val_accuracy: 0.4385 - val_loss: 1.2844 - val_precision: 0.7783 - val_recall: 0.1580 - learning_rate: 0.0010\nEpoch 13/50\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 474ms/step - accuracy: 0.4414 - loss: 1.2740 - precision: 0.7702 - recall: 0.1810 - val_accuracy: 0.4455 - val_loss: 1.2873 - val_precision: 0.7978 - val_recall: 0.1460 - learning_rate: 0.0010\nEpoch 14/50\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 490ms/step - accuracy: 0.4337 - loss: 1.2798 - precision: 0.7883 - recall: 0.1714 - val_accuracy: 0.4600 - val_loss: 1.2771 - val_precision: 0.7741 - val_recall: 0.1645 - learning_rate: 0.0010\nEpoch 15/50\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 517ms/step - accuracy: 0.4475 - loss: 1.2853 - precision: 0.7686 - recall: 0.1738 - val_accuracy: 0.4335 - val_loss: 1.2877 - val_precision: 0.7593 - val_recall: 0.1640 - learning_rate: 0.0010\nEpoch 16/50\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 509ms/step - accuracy: 0.4235 - loss: 1.2986 - precision: 0.7473 - recall: 0.1678 - val_accuracy: 0.4735 - val_loss: 1.2700 - val_precision: 0.7810 - val_recall: 0.1730 - learning_rate: 0.0010\nEpoch 17/50\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 500ms/step - accuracy: 0.4507 - loss: 1.2586 - precision: 0.7708 - recall: 0.1828 - val_accuracy: 0.4440 - val_loss: 1.2862 - val_precision: 0.7302 - val_recall: 0.1705 - learning_rate: 0.0010\nEpoch 18/50\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 492ms/step - accuracy: 0.4440 - loss: 1.2807 - precision: 0.7650 - recall: 0.1797 - val_accuracy: 0.4435 - val_loss: 1.2820 - val_precision: 0.7947 - val_recall: 0.1510 - learning_rate: 0.0010\nEpoch 19/50\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 488ms/step - accuracy: 0.4318 - loss: 1.2812 - precision: 0.7584 - recall: 0.1809 - val_accuracy: 0.4600 - val_loss: 1.2750 - val_precision: 0.7620 - val_recall: 0.1745 - learning_rate: 0.0010\nEpoch 20/50\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 488ms/step - accuracy: 0.4512 - loss: 1.2615 - precision: 0.7758 - recall: 0.1805 - val_accuracy: 0.4665 - val_loss: 1.2665 - val_precision: 0.7478 - val_recall: 0.1690 - learning_rate: 0.0010\nEpoch 21/50\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 488ms/step - accuracy: 0.4422 - loss: 1.2796 - precision: 0.7503 - recall: 0.1807 - val_accuracy: 0.4390 - val_loss: 1.2822 - val_precision: 0.7850 - val_recall: 0.1570 - learning_rate: 0.0010\nEpoch 22/50\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 492ms/step - accuracy: 0.4384 - loss: 1.2676 - precision: 0.7704 - recall: 0.1888 - val_accuracy: 0.4450 - val_loss: 1.2550 - val_precision: 0.8081 - val_recall: 0.1600 - learning_rate: 0.0010\nEpoch 23/50\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 487ms/step - accuracy: 0.4531 - loss: 1.2588 - precision: 0.7890 - recall: 0.1871 - val_accuracy: 0.4320 - val_loss: 1.2889 - val_precision: 0.7654 - val_recall: 0.1550 - learning_rate: 0.0010\nEpoch 24/50\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 486ms/step - accuracy: 0.4505 - loss: 1.2622 - precision: 0.7535 - recall: 0.1808 - val_accuracy: 0.4455 - val_loss: 1.2649 - val_precision: 0.7838 - val_recall: 0.1595 - learning_rate: 0.0010\nEpoch 25/50\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 491ms/step - accuracy: 0.4503 - loss: 1.2737 - precision: 0.7653 - recall: 0.1777 - val_accuracy: 0.4820 - val_loss: 1.2586 - val_precision: 0.7500 - val_recall: 0.1860 - learning_rate: 0.0010\nEpoch 26/50\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 495ms/step - accuracy: 0.4535 - loss: 1.2621 - precision: 0.7649 - recall: 0.1861 - val_accuracy: 0.4380 - val_loss: 1.2867 - val_precision: 0.7692 - val_recall: 0.1850 - learning_rate: 0.0010\nEpoch 27/50\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 491ms/step - accuracy: 0.4570 - loss: 1.2678 - precision: 0.7875 - recall: 0.1946 - val_accuracy: 0.4585 - val_loss: 1.2575 - val_precision: 0.7773 - val_recall: 0.1710 - learning_rate: 0.0010\nEpoch 28/50\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 490ms/step - accuracy: 0.4689 - loss: 1.2430 - precision: 0.7890 - recall: 0.2011 - val_accuracy: 0.4705 - val_loss: 1.2591 - val_precision: 0.7557 - val_recall: 0.1810 - learning_rate: 2.0000e-04\nEpoch 29/50\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 487ms/step - accuracy: 0.4578 - loss: 1.2456 - precision: 0.7972 - recall: 0.1907 - val_accuracy: 0.4715 - val_loss: 1.2447 - val_precision: 0.7765 - val_recall: 0.1720 - learning_rate: 2.0000e-04\nEpoch 30/50\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 486ms/step - accuracy: 0.4704 - loss: 1.2500 - precision: 0.7729 - recall: 0.1839 - val_accuracy: 0.4740 - val_loss: 1.2582 - val_precision: 0.7729 - val_recall: 0.1685 - learning_rate: 2.0000e-04\nEpoch 31/50\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 488ms/step - accuracy: 0.4702 - loss: 1.2495 - precision: 0.7769 - recall: 0.1910 - val_accuracy: 0.4805 - val_loss: 1.2475 - val_precision: 0.7737 - val_recall: 0.1675 - learning_rate: 2.0000e-04\nEpoch 32/50\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 484ms/step - accuracy: 0.4696 - loss: 1.2388 - precision: 0.7881 - recall: 0.1882 - val_accuracy: 0.4695 - val_loss: 1.2460 - val_precision: 0.7966 - val_recall: 0.1625 - learning_rate: 2.0000e-04\nEpoch 33/50\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 483ms/step - accuracy: 0.4525 - loss: 1.2550 - precision: 0.7831 - recall: 0.1840 - val_accuracy: 0.4635 - val_loss: 1.2529 - val_precision: 0.7921 - val_recall: 0.1600 - learning_rate: 2.0000e-04\nEpoch 34/50\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 484ms/step - accuracy: 0.4668 - loss: 1.2339 - precision: 0.7924 - recall: 0.1922 - val_accuracy: 0.4605 - val_loss: 1.2510 - val_precision: 0.7905 - val_recall: 0.1660 - learning_rate: 2.0000e-04\nEpoch 35/50\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 483ms/step - accuracy: 0.4539 - loss: 1.2533 - precision: 0.7906 - recall: 0.1850 - val_accuracy: 0.4680 - val_loss: 1.2461 - val_precision: 0.7842 - val_recall: 0.1635 - learning_rate: 1.0000e-04\nEpoch 36/50\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 486ms/step - accuracy: 0.4603 - loss: 1.2501 - precision: 0.7683 - recall: 0.1811 - val_accuracy: 0.4760 - val_loss: 1.2453 - val_precision: 0.7792 - val_recall: 0.1765 - learning_rate: 1.0000e-04\nEpoch 37/50\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 483ms/step - accuracy: 0.4731 - loss: 1.2202 - precision: 0.8193 - recall: 0.1956 - val_accuracy: 0.4675 - val_loss: 1.2467 - val_precision: 0.7914 - val_recall: 0.1745 - learning_rate: 1.0000e-04\nEpoch 38/50\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 486ms/step - accuracy: 0.4534 - loss: 1.2632 - precision: 0.7686 - recall: 0.1833 - val_accuracy: 0.4700 - val_loss: 1.2451 - val_precision: 0.7652 - val_recall: 0.1760 - learning_rate: 1.0000e-04\nEpoch 39/50\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 493ms/step - accuracy: 0.4681 - loss: 1.2399 - precision: 0.7844 - recall: 0.1881 - val_accuracy: 0.4700 - val_loss: 1.2513 - val_precision: 0.7759 - val_recall: 0.1645 - learning_rate: 1.0000e-04\n\nFine-tuning ResNet50 (unfreezing base model)...\nEpoch 1/20\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 571ms/step - accuracy: 0.4488 - loss: 4.5829 - precision: 0.5122 - recall: 0.3408 - val_accuracy: 0.2000 - val_loss: 7165.9233 - val_precision: 0.2000 - val_recall: 0.2000 - learning_rate: 1.0000e-04\nEpoch 2/20\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 516ms/step - accuracy: 0.6336 - loss: 0.9647 - precision: 0.7097 - recall: 0.5106 - val_accuracy: 0.2000 - val_loss: 1284.2760 - val_precision: 0.2000 - val_recall: 0.2000 - learning_rate: 1.0000e-04\nEpoch 3/20\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 525ms/step - accuracy: 0.6775 - loss: 0.8416 - precision: 0.7445 - recall: 0.5836 - val_accuracy: 0.2205 - val_loss: 12.0321 - val_precision: 0.2232 - val_recall: 0.2050 - learning_rate: 1.0000e-04\nEpoch 4/20\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 525ms/step - accuracy: 0.7186 - loss: 0.7381 - precision: 0.7791 - recall: 0.6500 - val_accuracy: 0.6360 - val_loss: 0.9049 - val_precision: 0.7005 - val_recall: 0.5345 - learning_rate: 1.0000e-04\nEpoch 5/20\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 532ms/step - accuracy: 0.7573 - loss: 0.6420 - precision: 0.7951 - recall: 0.6908 - val_accuracy: 0.6845 - val_loss: 1.1192 - val_precision: 0.7313 - val_recall: 0.6245 - learning_rate: 1.0000e-04\nEpoch 6/20\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 533ms/step - accuracy: 0.7788 - loss: 0.6018 - precision: 0.8136 - recall: 0.7323 - val_accuracy: 0.6500 - val_loss: 1.0447 - val_precision: 0.6847 - val_recall: 0.5875 - learning_rate: 1.0000e-04\nEpoch 7/20\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 527ms/step - accuracy: 0.8063 - loss: 0.5432 - precision: 0.8330 - recall: 0.7656 - val_accuracy: 0.7050 - val_loss: 0.9278 - val_precision: 0.7440 - val_recall: 0.6640 - learning_rate: 1.0000e-04\nEpoch 8/20\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 527ms/step - accuracy: 0.8290 - loss: 0.4600 - precision: 0.8573 - recall: 0.7957 - val_accuracy: 0.7790 - val_loss: 0.6100 - val_precision: 0.8006 - val_recall: 0.7490 - learning_rate: 1.0000e-04\nEpoch 9/20\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 525ms/step - accuracy: 0.8495 - loss: 0.3987 - precision: 0.8737 - recall: 0.8294 - val_accuracy: 0.7625 - val_loss: 0.7272 - val_precision: 0.7926 - val_recall: 0.7300 - learning_rate: 1.0000e-04\nEpoch 10/20\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 535ms/step - accuracy: 0.8778 - loss: 0.3388 - precision: 0.8946 - recall: 0.8577 - val_accuracy: 0.7255 - val_loss: 0.8590 - val_precision: 0.7399 - val_recall: 0.7070 - learning_rate: 1.0000e-04\nEpoch 11/20\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 529ms/step - accuracy: 0.8744 - loss: 0.3416 - precision: 0.8936 - recall: 0.8556 - val_accuracy: 0.7685 - val_loss: 0.6692 - val_precision: 0.7889 - val_recall: 0.7455 - learning_rate: 1.0000e-04\nEpoch 12/20\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 525ms/step - accuracy: 0.8829 - loss: 0.3317 - precision: 0.8949 - recall: 0.8661 - val_accuracy: 0.6135 - val_loss: 1.9232 - val_precision: 0.6240 - val_recall: 0.6000 - learning_rate: 1.0000e-04\nEpoch 13/20\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 532ms/step - accuracy: 0.8922 - loss: 0.3075 - precision: 0.9021 - recall: 0.8809 - val_accuracy: 0.7210 - val_loss: 0.7668 - val_precision: 0.7435 - val_recall: 0.7015 - learning_rate: 1.0000e-04\nEpoch 14/20\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 514ms/step - accuracy: 0.9090 - loss: 0.2529 - precision: 0.9150 - recall: 0.8986 - val_accuracy: 0.5290 - val_loss: 2.3548 - val_precision: 0.5344 - val_recall: 0.5200 - learning_rate: 1.0000e-04\nEpoch 15/20\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 524ms/step - accuracy: 0.9131 - loss: 0.2323 - precision: 0.9217 - recall: 0.9049 - val_accuracy: 0.7415 - val_loss: 0.8067 - val_precision: 0.7598 - val_recall: 0.7275 - learning_rate: 1.0000e-04\nEpoch 16/20\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 531ms/step - accuracy: 0.9249 - loss: 0.2261 - precision: 0.9314 - recall: 0.9160 - val_accuracy: 0.6770 - val_loss: 1.2701 - val_precision: 0.6861 - val_recall: 0.6635 - learning_rate: 1.0000e-04\nEpoch 17/20\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 519ms/step - accuracy: 0.9331 - loss: 0.1908 - precision: 0.9394 - recall: 0.9228 - val_accuracy: 0.6310 - val_loss: 1.5690 - val_precision: 0.6468 - val_recall: 0.6245 - learning_rate: 1.0000e-04\nEpoch 18/20\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 527ms/step - accuracy: 0.9393 - loss: 0.1712 - precision: 0.9446 - recall: 0.9324 - val_accuracy: 0.7970 - val_loss: 0.6858 - val_precision: 0.8055 - val_recall: 0.7890 - learning_rate: 1.0000e-04\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 453ms/step\n\nResNet50 Results:\nPrecision Matrix (Confusion Matrix):\n[[384   8   7   0   1]\n [  6 271  72  13  38]\n [  3  20 284  60  33]\n [  0   4  22 328  46]\n [  0   9  38  56 297]]\nClass-wise Precision: [0.97709924 0.86858974 0.6713948  0.71772429 0.71566265]\nMean Precision: 0.7901\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"\n\nfrom sklearn.metrics import accuracy_score\n\nresnet50_accuracy = accuracy_score(resnet50_true_classes, resnet50_pred_classes)\nprint(f\"Accuracy Score: {resnet50_accuracy:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T20:03:15.143488Z","iopub.execute_input":"2025-09-14T20:03:15.144329Z","iopub.status.idle":"2025-09-14T20:03:15.150433Z","shell.execute_reply.started":"2025-09-14T20:03:15.144296Z","shell.execute_reply":"2025-09-14T20:03:15.149721Z"}},"outputs":[{"name":"stdout","text":"Accuracy Score: 0.7820\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Accuracy from confusion matrix\ncorrect_predictions = np.trace(resnet50_cm)   # sum of diagonal values\ntotal_predictions = np.sum(resnet50_cm)\nresnet50_accuracy = correct_predictions / total_predictions\n\nprint(f\"Accuracy from Confusion Matrix: {resnet50_accuracy:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T20:03:54.820728Z","iopub.execute_input":"2025-09-14T20:03:54.821336Z","iopub.status.idle":"2025-09-14T20:03:54.825844Z","shell.execute_reply.started":"2025-09-14T20:03:54.821305Z","shell.execute_reply":"2025-09-14T20:03:54.825135Z"}},"outputs":[{"name":"stdout","text":"Accuracy from Confusion Matrix: 0.7820\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# CELL 2: ResNet152 Direct Implementation  \nprint(\"\\n\" + \"=\"*60)\nprint(\"RESNET152 MODEL ON APTOS DATASET\")\nprint(\"=\"*60)\n\n# Load ResNet152 pretrained model\nresnet152_base = ResNet152(\n    weights='imagenet',\n    include_top=False,\n    input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n)\n\n# Freeze the base model\nresnet152_base.trainable = False\n\n# Add classification head\nresnet152_model = keras.Sequential([\n    resnet152_base,\n    keras.layers.GlobalAveragePooling2D(),\n    keras.layers.Dropout(0.3),\n    keras.layers.Dense(256, activation='relu'),\n    keras.layers.Dropout(0.2),\n    keras.layers.Dense(NUM_CLASSES, activation='softmax')\n], name='ResNet152_APTOS')\n\n# Compile and train\nresnet152_model.compile(\n    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n    loss='categorical_crossentropy',\n    metrics=['accuracy', 'precision', 'recall']\n)\n\nprint(f\"ResNet152 Model: {resnet152_model.count_params():,} parameters\")\n\n# Train ResNet152\nresnet152_history = resnet152_model.fit(\n    train_generator,\n    epochs=70,\n    validation_data=validation_generator,\n    class_weight=class_weight_dict,\n    callbacks=[early_stopping, reduce_lr],\n    verbose=1\n)\n\n# Fine-tune ResNet152\nresnet152_base.trainable = True\nresnet152_model.compile(\n    optimizer=keras.optimizers.Adam(learning_rate=0.00005),\n    loss='categorical_crossentropy',\n    metrics=['accuracy', 'precision', 'recall']\n)\n\nresnet152_history_fine = resnet152_model.fit(\n    train_generator,\n    epochs=15,\n    validation_data=validation_generator,\n    class_weight=class_weight_dict,\n    callbacks=[early_stopping, reduce_lr],\n    verbose=1\n)\n\n# Calculate precision matrix\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T05:46:02.971827Z","iopub.execute_input":"2025-09-15T05:46:02.972419Z","iopub.status.idle":"2025-09-15T08:27:57.726691Z","shell.execute_reply.started":"2025-09-15T05:46:02.972394Z","shell.execute_reply":"2025-09-15T08:27:57.725708Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nRESNET152 MODEL ON APTOS DATASET\n============================================================\nResNet152 Model: 58,896,773 parameters\nEpoch 1/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 557ms/step - accuracy: 0.3290 - loss: 1.4959 - precision: 0.6477 - recall: 0.1146 - val_accuracy: 0.3565 - val_loss: 1.3754 - val_precision: 0.8773 - val_recall: 0.1215 - learning_rate: 0.0010\nEpoch 2/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 487ms/step - accuracy: 0.3680 - loss: 1.3808 - precision: 0.8111 - recall: 0.1278 - val_accuracy: 0.3595 - val_loss: 1.3490 - val_precision: 0.8852 - val_recall: 0.1195 - learning_rate: 0.0010\nEpoch 3/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 480ms/step - accuracy: 0.3945 - loss: 1.3406 - precision: 0.8344 - recall: 0.1373 - val_accuracy: 0.4140 - val_loss: 1.3172 - val_precision: 0.8207 - val_recall: 0.1350 - learning_rate: 0.0010\nEpoch 4/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 482ms/step - accuracy: 0.4176 - loss: 1.3161 - precision: 0.8001 - recall: 0.1541 - val_accuracy: 0.3985 - val_loss: 1.3137 - val_precision: 0.8215 - val_recall: 0.1335 - learning_rate: 0.0010\nEpoch 5/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 483ms/step - accuracy: 0.4088 - loss: 1.3217 - precision: 0.8021 - recall: 0.1494 - val_accuracy: 0.4325 - val_loss: 1.2916 - val_precision: 0.8509 - val_recall: 0.1370 - learning_rate: 0.0010\nEpoch 6/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 484ms/step - accuracy: 0.4090 - loss: 1.3215 - precision: 0.7971 - recall: 0.1469 - val_accuracy: 0.4110 - val_loss: 1.3106 - val_precision: 0.8632 - val_recall: 0.1325 - learning_rate: 0.0010\nEpoch 7/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 485ms/step - accuracy: 0.4096 - loss: 1.3166 - precision: 0.7903 - recall: 0.1535 - val_accuracy: 0.4375 - val_loss: 1.2924 - val_precision: 0.7984 - val_recall: 0.1465 - learning_rate: 0.0010\nEpoch 8/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 481ms/step - accuracy: 0.4306 - loss: 1.2853 - precision: 0.7770 - recall: 0.1669 - val_accuracy: 0.4380 - val_loss: 1.3024 - val_precision: 0.8247 - val_recall: 0.1435 - learning_rate: 0.0010\nEpoch 9/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 483ms/step - accuracy: 0.4170 - loss: 1.3050 - precision: 0.8127 - recall: 0.1641 - val_accuracy: 0.4055 - val_loss: 1.3051 - val_precision: 0.7952 - val_recall: 0.1495 - learning_rate: 0.0010\nEpoch 10/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 480ms/step - accuracy: 0.4318 - loss: 1.3019 - precision: 0.7864 - recall: 0.1718 - val_accuracy: 0.4320 - val_loss: 1.2835 - val_precision: 0.8407 - val_recall: 0.1425 - learning_rate: 0.0010\nEpoch 11/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 481ms/step - accuracy: 0.4221 - loss: 1.2964 - precision: 0.7923 - recall: 0.1595 - val_accuracy: 0.4180 - val_loss: 1.2744 - val_precision: 0.8635 - val_recall: 0.1455 - learning_rate: 0.0010\nEpoch 12/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 493ms/step - accuracy: 0.4135 - loss: 1.3067 - precision: 0.7889 - recall: 0.1585 - val_accuracy: 0.4230 - val_loss: 1.2880 - val_precision: 0.8125 - val_recall: 0.1495 - learning_rate: 0.0010\nEpoch 13/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 477ms/step - accuracy: 0.4496 - loss: 1.2663 - precision: 0.7814 - recall: 0.1835 - val_accuracy: 0.4130 - val_loss: 1.3079 - val_precision: 0.7854 - val_recall: 0.1665 - learning_rate: 0.0010\nEpoch 14/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 487ms/step - accuracy: 0.4257 - loss: 1.3004 - precision: 0.8022 - recall: 0.1543 - val_accuracy: 0.4495 - val_loss: 1.2612 - val_precision: 0.8379 - val_recall: 0.1525 - learning_rate: 0.0010\nEpoch 15/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 482ms/step - accuracy: 0.4430 - loss: 1.2845 - precision: 0.7766 - recall: 0.1714 - val_accuracy: 0.4615 - val_loss: 1.2597 - val_precision: 0.7959 - val_recall: 0.1735 - learning_rate: 0.0010\nEpoch 16/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 482ms/step - accuracy: 0.4465 - loss: 1.2641 - precision: 0.7834 - recall: 0.1912 - val_accuracy: 0.4415 - val_loss: 1.2798 - val_precision: 0.9149 - val_recall: 0.1290 - learning_rate: 0.0010\nEpoch 17/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 484ms/step - accuracy: 0.4158 - loss: 1.2946 - precision: 0.7917 - recall: 0.1563 - val_accuracy: 0.4705 - val_loss: 1.2619 - val_precision: 0.8024 - val_recall: 0.1645 - learning_rate: 0.0010\nEpoch 18/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 484ms/step - accuracy: 0.4339 - loss: 1.2903 - precision: 0.7617 - recall: 0.1643 - val_accuracy: 0.4660 - val_loss: 1.2668 - val_precision: 0.8117 - val_recall: 0.1530 - learning_rate: 0.0010\nEpoch 19/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 483ms/step - accuracy: 0.4409 - loss: 1.2655 - precision: 0.7890 - recall: 0.1702 - val_accuracy: 0.4340 - val_loss: 1.2711 - val_precision: 0.7639 - val_recall: 0.1780 - learning_rate: 0.0010\nEpoch 20/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 485ms/step - accuracy: 0.4379 - loss: 1.2834 - precision: 0.7757 - recall: 0.1822 - val_accuracy: 0.4530 - val_loss: 1.2671 - val_precision: 0.8088 - val_recall: 0.1565 - learning_rate: 0.0010\nEpoch 21/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 480ms/step - accuracy: 0.4535 - loss: 1.2650 - precision: 0.7730 - recall: 0.1775 - val_accuracy: 0.4630 - val_loss: 1.2518 - val_precision: 0.7796 - val_recall: 0.1645 - learning_rate: 2.0000e-04\nEpoch 22/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 490ms/step - accuracy: 0.4427 - loss: 1.2766 - precision: 0.7873 - recall: 0.1777 - val_accuracy: 0.4555 - val_loss: 1.2622 - val_precision: 0.8050 - val_recall: 0.1610 - learning_rate: 2.0000e-04\nEpoch 23/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 487ms/step - accuracy: 0.4524 - loss: 1.2597 - precision: 0.7889 - recall: 0.1815 - val_accuracy: 0.4550 - val_loss: 1.2487 - val_precision: 0.7916 - val_recall: 0.1595 - learning_rate: 2.0000e-04\nEpoch 24/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 481ms/step - accuracy: 0.4618 - loss: 1.2517 - precision: 0.7697 - recall: 0.1875 - val_accuracy: 0.4670 - val_loss: 1.2512 - val_precision: 0.8094 - val_recall: 0.1635 - learning_rate: 2.0000e-04\nEpoch 25/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 483ms/step - accuracy: 0.4532 - loss: 1.2653 - precision: 0.7728 - recall: 0.1789 - val_accuracy: 0.4495 - val_loss: 1.2650 - val_precision: 0.7951 - val_recall: 0.1630 - learning_rate: 2.0000e-04\nEpoch 26/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 500ms/step - accuracy: 0.4511 - loss: 1.2718 - precision: 0.7920 - recall: 0.1832 - val_accuracy: 0.4550 - val_loss: 1.2593 - val_precision: 0.7749 - val_recall: 0.1670 - learning_rate: 2.0000e-04\nEpoch 27/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 500ms/step - accuracy: 0.4482 - loss: 1.2509 - precision: 0.7783 - recall: 0.1855 - val_accuracy: 0.4525 - val_loss: 1.2445 - val_precision: 0.7828 - val_recall: 0.1640 - learning_rate: 2.0000e-04\nEpoch 28/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 506ms/step - accuracy: 0.4428 - loss: 1.2659 - precision: 0.7764 - recall: 0.1788 - val_accuracy: 0.4600 - val_loss: 1.2407 - val_precision: 0.8051 - val_recall: 0.1590 - learning_rate: 2.0000e-04\nEpoch 29/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 492ms/step - accuracy: 0.4588 - loss: 1.2612 - precision: 0.7839 - recall: 0.1777 - val_accuracy: 0.4625 - val_loss: 1.2455 - val_precision: 0.7901 - val_recall: 0.1675 - learning_rate: 2.0000e-04\nEpoch 30/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 480ms/step - accuracy: 0.4464 - loss: 1.2653 - precision: 0.7976 - recall: 0.1786 - val_accuracy: 0.4785 - val_loss: 1.2474 - val_precision: 0.8186 - val_recall: 0.1625 - learning_rate: 2.0000e-04\nEpoch 31/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 481ms/step - accuracy: 0.4566 - loss: 1.2445 - precision: 0.7987 - recall: 0.1822 - val_accuracy: 0.4575 - val_loss: 1.2380 - val_precision: 0.8048 - val_recall: 0.1670 - learning_rate: 2.0000e-04\nEpoch 32/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 486ms/step - accuracy: 0.4475 - loss: 1.2668 - precision: 0.7936 - recall: 0.1800 - val_accuracy: 0.4555 - val_loss: 1.2568 - val_precision: 0.8035 - val_recall: 0.1615 - learning_rate: 2.0000e-04\nEpoch 33/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 495ms/step - accuracy: 0.4467 - loss: 1.2695 - precision: 0.7931 - recall: 0.1809 - val_accuracy: 0.4750 - val_loss: 1.2391 - val_precision: 0.8084 - val_recall: 0.1645 - learning_rate: 2.0000e-04\nEpoch 34/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 486ms/step - accuracy: 0.4643 - loss: 1.2373 - precision: 0.7858 - recall: 0.1925 - val_accuracy: 0.4670 - val_loss: 1.2396 - val_precision: 0.8278 - val_recall: 0.1610 - learning_rate: 2.0000e-04\nEpoch 35/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 481ms/step - accuracy: 0.4492 - loss: 1.2611 - precision: 0.7755 - recall: 0.1742 - val_accuracy: 0.4590 - val_loss: 1.2447 - val_precision: 0.7880 - val_recall: 0.1635 - learning_rate: 2.0000e-04\nEpoch 36/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 483ms/step - accuracy: 0.4487 - loss: 1.2564 - precision: 0.7820 - recall: 0.1788 - val_accuracy: 0.4560 - val_loss: 1.2530 - val_precision: 0.7733 - val_recall: 0.1740 - learning_rate: 2.0000e-04\nEpoch 37/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 481ms/step - accuracy: 0.4551 - loss: 1.2387 - precision: 0.7823 - recall: 0.2037 - val_accuracy: 0.4605 - val_loss: 1.2359 - val_precision: 0.7972 - val_recall: 0.1710 - learning_rate: 1.0000e-04\nEpoch 38/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 493ms/step - accuracy: 0.4523 - loss: 1.2548 - precision: 0.7796 - recall: 0.1832 - val_accuracy: 0.4710 - val_loss: 1.2364 - val_precision: 0.7802 - val_recall: 0.1775 - learning_rate: 1.0000e-04\nEpoch 39/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 487ms/step - accuracy: 0.4481 - loss: 1.2712 - precision: 0.7599 - recall: 0.1831 - val_accuracy: 0.4610 - val_loss: 1.2389 - val_precision: 0.8077 - val_recall: 0.1680 - learning_rate: 1.0000e-04\nEpoch 40/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 483ms/step - accuracy: 0.4602 - loss: 1.2601 - precision: 0.7608 - recall: 0.1878 - val_accuracy: 0.4745 - val_loss: 1.2369 - val_precision: 0.7874 - val_recall: 0.1685 - learning_rate: 1.0000e-04\nEpoch 41/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 484ms/step - accuracy: 0.4515 - loss: 1.2478 - precision: 0.7817 - recall: 0.1855 - val_accuracy: 0.4705 - val_loss: 1.2392 - val_precision: 0.8037 - val_recall: 0.1720 - learning_rate: 1.0000e-04\nEpoch 42/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 486ms/step - accuracy: 0.4481 - loss: 1.2540 - precision: 0.7769 - recall: 0.1868 - val_accuracy: 0.4800 - val_loss: 1.2417 - val_precision: 0.8193 - val_recall: 0.1655 - learning_rate: 1.0000e-04\nEpoch 43/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 484ms/step - accuracy: 0.4486 - loss: 1.2424 - precision: 0.7997 - recall: 0.1911 - val_accuracy: 0.4690 - val_loss: 1.2386 - val_precision: 0.7915 - val_recall: 0.1670 - learning_rate: 1.0000e-04\nEpoch 44/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 480ms/step - accuracy: 0.4592 - loss: 1.2468 - precision: 0.7664 - recall: 0.1922 - val_accuracy: 0.4765 - val_loss: 1.2380 - val_precision: 0.7755 - val_recall: 0.1675 - learning_rate: 1.0000e-04\nEpoch 45/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 487ms/step - accuracy: 0.4539 - loss: 1.2583 - precision: 0.7614 - recall: 0.1828 - val_accuracy: 0.4775 - val_loss: 1.2461 - val_precision: 0.8009 - val_recall: 0.1730 - learning_rate: 1.0000e-04\nEpoch 46/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 486ms/step - accuracy: 0.4528 - loss: 1.2477 - precision: 0.7832 - recall: 0.1924 - val_accuracy: 0.4780 - val_loss: 1.2310 - val_precision: 0.7922 - val_recall: 0.1735 - learning_rate: 1.0000e-04\nEpoch 47/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 486ms/step - accuracy: 0.4509 - loss: 1.2450 - precision: 0.7965 - recall: 0.1904 - val_accuracy: 0.4740 - val_loss: 1.2425 - val_precision: 0.7835 - val_recall: 0.1665 - learning_rate: 1.0000e-04\nEpoch 48/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 496ms/step - accuracy: 0.4546 - loss: 1.2574 - precision: 0.7667 - recall: 0.1842 - val_accuracy: 0.4795 - val_loss: 1.2336 - val_precision: 0.7795 - val_recall: 0.1715 - learning_rate: 1.0000e-04\nEpoch 49/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 482ms/step - accuracy: 0.4587 - loss: 1.2420 - precision: 0.7907 - recall: 0.1944 - val_accuracy: 0.4805 - val_loss: 1.2326 - val_precision: 0.8269 - val_recall: 0.1720 - learning_rate: 1.0000e-04\nEpoch 50/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 476ms/step - accuracy: 0.4411 - loss: 1.2486 - precision: 0.7982 - recall: 0.1917 - val_accuracy: 0.4600 - val_loss: 1.2466 - val_precision: 0.7879 - val_recall: 0.1765 - learning_rate: 1.0000e-04\nEpoch 51/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 483ms/step - accuracy: 0.4577 - loss: 1.2597 - precision: 0.7806 - recall: 0.1874 - val_accuracy: 0.4720 - val_loss: 1.2310 - val_precision: 0.7976 - val_recall: 0.1695 - learning_rate: 1.0000e-04\nEpoch 52/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 485ms/step - accuracy: 0.4484 - loss: 1.2489 - precision: 0.7735 - recall: 0.1967 - val_accuracy: 0.4805 - val_loss: 1.2237 - val_precision: 0.7879 - val_recall: 0.1765 - learning_rate: 1.0000e-04\nEpoch 53/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 490ms/step - accuracy: 0.4564 - loss: 1.2633 - precision: 0.7705 - recall: 0.1870 - val_accuracy: 0.4770 - val_loss: 1.2337 - val_precision: 0.7967 - val_recall: 0.1685 - learning_rate: 1.0000e-04\nEpoch 54/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 484ms/step - accuracy: 0.4344 - loss: 1.2663 - precision: 0.7695 - recall: 0.1778 - val_accuracy: 0.4685 - val_loss: 1.2297 - val_precision: 0.7920 - val_recall: 0.1675 - learning_rate: 1.0000e-04\nEpoch 55/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 482ms/step - accuracy: 0.4459 - loss: 1.2598 - precision: 0.7764 - recall: 0.1885 - val_accuracy: 0.4685 - val_loss: 1.2371 - val_precision: 0.8166 - val_recall: 0.1670 - learning_rate: 1.0000e-04\nEpoch 56/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 498ms/step - accuracy: 0.4564 - loss: 1.2659 - precision: 0.7711 - recall: 0.1780 - val_accuracy: 0.4640 - val_loss: 1.2357 - val_precision: 0.8028 - val_recall: 0.1710 - learning_rate: 1.0000e-04\nEpoch 57/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 498ms/step - accuracy: 0.4506 - loss: 1.2449 - precision: 0.7865 - recall: 0.1878 - val_accuracy: 0.4700 - val_loss: 1.2371 - val_precision: 0.7909 - val_recall: 0.1740 - learning_rate: 1.0000e-04\nEpoch 58/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 485ms/step - accuracy: 0.4593 - loss: 1.2380 - precision: 0.8064 - recall: 0.1968 - val_accuracy: 0.4670 - val_loss: 1.2364 - val_precision: 0.7874 - val_recall: 0.1685 - learning_rate: 1.0000e-04\nEpoch 59/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 482ms/step - accuracy: 0.4607 - loss: 1.2543 - precision: 0.7710 - recall: 0.1870 - val_accuracy: 0.4680 - val_loss: 1.2415 - val_precision: 0.7943 - val_recall: 0.1660 - learning_rate: 1.0000e-04\nEpoch 60/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 484ms/step - accuracy: 0.4532 - loss: 1.2390 - precision: 0.7937 - recall: 0.1936 - val_accuracy: 0.4715 - val_loss: 1.2348 - val_precision: 0.8166 - val_recall: 0.1670 - learning_rate: 1.0000e-04\nEpoch 61/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 487ms/step - accuracy: 0.4605 - loss: 1.2517 - precision: 0.7840 - recall: 0.1864 - val_accuracy: 0.4640 - val_loss: 1.2361 - val_precision: 0.7845 - val_recall: 0.1675 - learning_rate: 1.0000e-04\nEpoch 62/70\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 479ms/step - accuracy: 0.4571 - loss: 1.2381 - precision: 0.7784 - recall: 0.1944 - val_accuracy: 0.4675 - val_loss: 1.2351 - val_precision: 0.8203 - val_recall: 0.1620 - learning_rate: 1.0000e-04\nEpoch 1/15\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 560ms/step - accuracy: 0.3875 - loss: 6.3979 - precision: 0.4800 - recall: 0.2750 - val_accuracy: 0.2000 - val_loss: 932.5814 - val_precision: 0.2000 - val_recall: 0.2000 - learning_rate: 5.0000e-05\nEpoch 2/15\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 498ms/step - accuracy: 0.5217 - loss: 1.0930 - precision: 0.7541 - recall: 0.2877 - val_accuracy: 0.2000 - val_loss: 138.6123 - val_precision: 0.2000 - val_recall: 0.2000 - learning_rate: 5.0000e-05\nEpoch 3/15\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 496ms/step - accuracy: 0.6043 - loss: 0.9314 - precision: 0.7317 - recall: 0.4284 - val_accuracy: 0.2765 - val_loss: 2.9048 - val_precision: 0.3185 - val_recall: 0.1970 - learning_rate: 5.0000e-05\nEpoch 4/15\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 496ms/step - accuracy: 0.6290 - loss: 0.8970 - precision: 0.7243 - recall: 0.4669 - val_accuracy: 0.5345 - val_loss: 1.1261 - val_precision: 0.6437 - val_recall: 0.3830 - learning_rate: 5.0000e-05\nEpoch 5/15\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 496ms/step - accuracy: 0.6771 - loss: 0.7618 - precision: 0.7627 - recall: 0.5841 - val_accuracy: 0.6750 - val_loss: 0.8422 - val_precision: 0.7468 - val_recall: 0.5810 - learning_rate: 5.0000e-05\nEpoch 6/15\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 497ms/step - accuracy: 0.7125 - loss: 0.6943 - precision: 0.7791 - recall: 0.6241 - val_accuracy: 0.6950 - val_loss: 0.7302 - val_precision: 0.7590 - val_recall: 0.6455 - learning_rate: 5.0000e-05\nEpoch 7/15\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 494ms/step - accuracy: 0.7425 - loss: 0.6327 - precision: 0.7963 - recall: 0.6710 - val_accuracy: 0.7055 - val_loss: 0.7466 - val_precision: 0.7607 - val_recall: 0.6245 - learning_rate: 5.0000e-05\nEpoch 8/15\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 495ms/step - accuracy: 0.7659 - loss: 0.5931 - precision: 0.8132 - recall: 0.6965 - val_accuracy: 0.7545 - val_loss: 0.6458 - val_precision: 0.7906 - val_recall: 0.7135 - learning_rate: 5.0000e-05\nEpoch 9/15\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 487ms/step - accuracy: 0.8041 - loss: 0.5022 - precision: 0.8414 - recall: 0.7638 - val_accuracy: 0.7545 - val_loss: 0.6496 - val_precision: 0.7865 - val_recall: 0.7185 - learning_rate: 5.0000e-05\nEpoch 10/15\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 494ms/step - accuracy: 0.8214 - loss: 0.4725 - precision: 0.8517 - recall: 0.7871 - val_accuracy: 0.8000 - val_loss: 0.5502 - val_precision: 0.8199 - val_recall: 0.7760 - learning_rate: 5.0000e-05\nEpoch 11/15\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 495ms/step - accuracy: 0.8451 - loss: 0.4006 - precision: 0.8660 - recall: 0.8179 - val_accuracy: 0.7890 - val_loss: 0.5506 - val_precision: 0.8155 - val_recall: 0.7580 - learning_rate: 5.0000e-05\nEpoch 12/15\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 515ms/step - accuracy: 0.8689 - loss: 0.3544 - precision: 0.8891 - recall: 0.8516 - val_accuracy: 0.8120 - val_loss: 0.4996 - val_precision: 0.8325 - val_recall: 0.7925 - learning_rate: 5.0000e-05\nEpoch 13/15\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 502ms/step - accuracy: 0.8768 - loss: 0.3371 - precision: 0.8941 - recall: 0.8611 - val_accuracy: 0.7655 - val_loss: 0.6584 - val_precision: 0.7890 - val_recall: 0.7440 - learning_rate: 5.0000e-05\nEpoch 14/15\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 508ms/step - accuracy: 0.8991 - loss: 0.2793 - precision: 0.9109 - recall: 0.8879 - val_accuracy: 0.8095 - val_loss: 0.5237 - val_precision: 0.8234 - val_recall: 0.7950 - learning_rate: 5.0000e-05\nEpoch 15/15\n\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 509ms/step - accuracy: 0.8927 - loss: 0.2839 - precision: 0.9026 - recall: 0.8816 - val_accuracy: 0.8345 - val_loss: 0.4923 - val_precision: 0.8471 - val_recall: 0.8225 - learning_rate: 5.0000e-05\n\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 545ms/step\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/2695192752.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0mresnet152_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet152_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mresnet152_pred_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet152_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mresnet152_cm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet50_true_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresnet152_pred_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0mresnet152_precision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet50_true_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresnet152_pred_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'resnet50_true_classes' is not defined"],"ename":"NameError","evalue":"name 'resnet50_true_classes' is not defined","output_type":"error"}],"execution_count":4},{"cell_type":"code","source":"\nfrom sklearn.metrics import accuracy_score\nval_loss, val_acc, val_precision, val_recall = resnet152_model.evaluate(validation_generator, verbose=1)\nprint(f\"Validation Accuracy (Keras evaluate): {val_acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T08:33:41.815824Z","iopub.execute_input":"2025-09-15T08:33:41.816142Z","iopub.status.idle":"2025-09-15T08:34:06.741577Z","shell.execute_reply.started":"2025-09-15T08:33:41.816119Z","shell.execute_reply":"2025-09-15T08:34:06.740993Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 381ms/step - accuracy: 0.8840 - loss: 0.3535 - precision: 0.8913 - recall: 0.8740\nValidation Accuracy (Keras evaluate): 0.8215\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 3: DenseNet121 Direct Implementation\nprint(\"\\n\" + \"=\"*60)\nprint(\"DENSENET121 MODEL ON APTOS DATASET\")\nprint(\"=\"*60)\n\n# Load DenseNet121 pretrained model\ndensenet121_base = DenseNet121(\n    weights='imagenet',\n    include_top=False,\n    input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n)\n\n# Freeze the base model\ndensenet121_base.trainable = False\n\n# Add classification head\ndensenet121_model = keras.Sequential([\n    densenet121_base,\n    keras.layers.GlobalAveragePooling2D(),\n    keras.layers.Dropout(0.3),\n    keras.layers.Dense(512, activation='relu'),\n    keras.layers.Dropout(0.2),\n    keras.layers.Dense(NUM_CLASSES, activation='softmax')\n], name='DenseNet121_APTOS')\n\n# Compile and train\ndensenet121_model.compile(\n    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n    loss='categorical_crossentropy',\n    metrics=['accuracy', 'precision', 'recall']\n)\n\nprint(f\"DenseNet121 Model: {densenet121_model.count_params():,} parameters\")\n\n# Train DenseNet121\ndensenet121_history = densenet121_model.fit(\n    train_generator,\n    epochs=10,\n    validation_data=validation_generator,\n    class_weight=class_weight_dict,\n    callbacks=[early_stopping, reduce_lr],\n    verbose=1\n)\n\n# Fine-tune DenseNet121\ndensenet121_base.trainable = True\ndensenet121_model.compile(\n    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n    loss='categorical_crossentropy',\n    metrics=['accuracy', 'precision', 'recall']\n)\n\ndensenet121_history_fine = densenet121_model.fit(\n    train_generator,\n    epochs=20,\n    validation_data=validation_generator,\n    class_weight=class_weight_dict,\n    callbacks=[early_stopping, reduce_lr],\n    verbose=1\n)\n\n# Calculate precision matrix\n# densenet121_predictions = densenet121_model.predict(validation_generator)\n# densenet121_pred_classes = np.argmax(densenet121_predictions, axis=1)\n# densenet121_cm = confusion_matrix(resnet50_true_classes, densenet121_pred_classes)\n# densenet121_precision = precision_score(resnet50_true_classes, densenet121_pred_classes, average=None, zero_division=0)\n\n# print(\"\\nDenseNet121 Results:\")\n# print(\"Precision Matrix (Confusion Matrix):\")\n# print(densenet121_cm)\n# print(f\"Class-wise Precision: {densenet121_precision}\")\n# print(f\"Mean Precision: {np.mean(densenet121_precision):.4f}\")\n\n# Save all models\n# resnet50_model.save('resnet50_aptos_model.h5')\n# resnet152_model.save('resnet152_aptos_model.h5')\n\n\nprint(\"\\nâœ… All models trained and saved successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T14:43:03.532034Z","iopub.execute_input":"2025-09-15T14:43:03.532550Z","iopub.status.idle":"2025-09-15T14:43:03.537064Z","shell.execute_reply.started":"2025-09-15T14:43:03.532529Z","shell.execute_reply":"2025-09-15T14:43:03.536425Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"densenet121_model.save('densenet121_aptos_model.h5')\n\nimport numpy as np\n# correct_predictions = np.trace(densenet121_cm)   # diagonal sum\n# total_predictions = np.sum(densenet121_cm)\n# densenet121_accuracy_cm = correct_predictions / total_predictions\n# print(f\"Accuracy from Confusion Matrix: {densenet121_accuracy_cm:.4f}\")\n\n# âœ… Accuracy directly from Keras evaluate (alternative check)\nval_loss, val_acc, val_precision, val_recall = densenet121_model.evaluate(validation_generator, verbose=1)\nprint(f\"Validation Accuracy (Keras evaluate): {val_acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T14:42:05.746598Z","iopub.execute_input":"2025-09-15T14:42:05.747132Z","iopub.status.idle":"2025-09-15T14:42:31.027326Z","shell.execute_reply.started":"2025-09-15T14:42:05.747105Z","shell.execute_reply":"2025-09-15T14:42:31.026747Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 369ms/step - accuracy: 0.8968 - loss: 0.3153 - precision: 0.9019 - recall: 0.8923\nValidation Accuracy (Keras evaluate): 0.8590\n","output_type":"stream"}],"execution_count":5}]}