{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"datasetVersion","sourceId":629378,"datasetId":309764,"databundleVersionId":648560}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import kagglehub\nimport os\nimport cv2\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, cohen_kappa_score, roc_auc_score\nfrom sklearn.model_selection import train_test_split\n\n# 1. Load dataset with memory efficiency\ndataset_path = kagglehub.dataset_download(\"aitude/aptos-augmented-images\")\nprint(\"Dataset Path:\", dataset_path)\n\nall_images = []\nall_labels = []\n\n# Walk through folders and only load a subset first to prevent OOM\nmax_images_per_class = 500  # limit per class to avoid memory crash\n\nfor root, dirs, files in os.walk(dataset_path):\n    label_name = os.path.basename(root)\n    if label_name == os.path.basename(dataset_path):\n        continue\n    count = 0\n    for file in files:\n        if file.lower().endswith((\".jpg\", \".png\", \".jpeg\")):\n            if count >= max_images_per_class:\n                break\n            img_path = os.path.join(root, file)\n            img = cv2.imread(img_path)\n            if img is None:\n                continue\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            img = cv2.resize(img, (128,128))  # reduce resolution to save memory\n            img = img.astype(np.float32) / 255.0\n            all_images.append(img)\n            all_labels.append(label_name)\n            count += 1\n    if count > 0:\n        print(f\"Loaded {count} images for label {label_name}\")\n\nX = np.array(all_images)\nlabel_to_idx = {label: idx for idx, label in enumerate(sorted(set(all_labels)))}\ny = np.array([label_to_idx[l] for l in all_labels])\n\nprint(\"Dataset loaded:\", X.shape, y.shape, \"Unique labels:\", np.unique(y))\n\nif X.shape[0] == 0:\n    raise RuntimeError(\"No images loaded. Check dataset structure and image formats.\")\n\n# 2. Build lightweight CNN feature extractor\ndef build_cnn():\n    model = models.Sequential([\n        layers.Conv2D(16, (3,3), activation='relu', input_shape=(128,128,3)),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D(2,2),\n\n        layers.Conv2D(32, (3,3), activation='relu'),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D(2,2),\n\n        layers.Conv2D(64, (3,3), activation='relu'),\n        layers.BatchNormalization(),\n        layers.GlobalAveragePooling2D(),\n\n        layers.Dense(64, activation='relu'),\n        layers.Dropout(0.3),\n        layers.Dense(32, activation='relu')\n    ])\n    return model\n\ncnn_model = build_cnn()\n\n# Extract features in batches to reduce memory usage\nprint(\"Extracting features with CNN...\")\nfeatures = cnn_model.predict(tf.data.Dataset.from_tensor_slices(X).batch(32), verbose=1)\n\n# 3. Ensemble SVM classifier\nsvm1 = SVC(kernel='linear', probability=True)\nsvm2 = SVC(kernel='rbf', probability=True)\nsvm3 = SVC(kernel='poly', degree=3, probability=True)\n\nensemble_svm = VotingClassifier(estimators=[('svm1', svm1), ('svm2', svm2), ('svm3', svm3)], voting='soft')\n\n# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(features, y, test_size=0.2, random_state=42, stratify=y)\n\nensemble_svm.fit(X_train, y_train)\n\n# Predictions\ny_pred = ensemble_svm.predict(X_test)\ny_prob = ensemble_svm.predict_proba(X_test)\n\n# 4. Evaluation\nacc = accuracy_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred, average='macro')\nprecision = precision_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\nkappa = cohen_kappa_score(y_test, y_pred)\nauc = roc_auc_score(y_test, y_prob, multi_class='ovr')\n\nprint(\"Accuracy:\", acc)\nprint(\"Recall (Sensitivity):\", recall)\nprint(\"Precision:\", precision)\nprint(\"F1 Score:\", f1)\nprint(\"Cohen Kappa:\", kappa)\nprint(\"AUC:\", auc)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T14:40:04.757154Z","iopub.execute_input":"2025-09-12T14:40:04.757933Z","iopub.status.idle":"2025-09-12T14:41:20.180040Z","shell.execute_reply.started":"2025-09-12T14:40:04.757898Z","shell.execute_reply":"2025-09-12T14:41:20.179197Z"}},"outputs":[{"name":"stdout","text":"Dataset Path: /kaggle/input/aptos-augmented-images\nLoaded 500 images for label 2\nLoaded 500 images for label 0\nLoaded 500 images for label 3\nLoaded 500 images for label 1\nLoaded 500 images for label 4\nLoaded 500 images for label 2\nLoaded 500 images for label 0\nLoaded 500 images for label 3\nLoaded 500 images for label 1\nLoaded 500 images for label 4\nDataset loaded: (5000, 128, 128, 3) (5000,) Unique labels: [0 1 2 3 4]\nExtracting features with CNN...\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1757688064.567732     771 service.cc:148] XLA service 0x7a7fc4003f70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1757688064.569012     771 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1757688064.569034     771 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 38/157\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1757688065.453730     771 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step\nAccuracy: 0.413\nRecall (Sensitivity): 0.413\nPrecision: 0.3936715107699323\nF1 Score: 0.3910225750691553\nCohen Kappa: 0.26625\nAUC: 0.7291274999999999\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import kagglehub\nimport os\nimport cv2\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, cohen_kappa_score, roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom skimage.filters import threshold_otsu\n\n# 1. Load dataset with memory efficiency\ndataset_path = kagglehub.dataset_download(\"aitude/aptos-augmented-images\")\nprint(\"Dataset Path:\", dataset_path)\n\nall_images = []\nall_labels = []\n\n# Walk through folders and only load a subset first to prevent OOM\nmax_images_per_class = 500  # limit per class to avoid memory crash\n\n# --- Fuzzy entropy preprocessing helper ---\ndef fuzzy_entropy_preprocess(img):\n    # Convert to grayscale\n    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n    # Normalize\n    gray = gray.astype(np.float32) / 255.0\n    # Compute global threshold using Otsu (approximation for fuzzy entropy thresholding)\n    thresh = threshold_otsu(gray)\n    mask = (gray > thresh).astype(np.float32)\n    # Apply mask back to 3-channel image\n    proc = img * mask[..., None]\n    return proc\n\nfor root, dirs, files in os.walk(dataset_path):\n    label_name = os.path.basename(root)\n    if label_name == os.path.basename(dataset_path):\n        continue\n    count = 0\n    for file in files:\n        if file.lower().endswith((\".jpg\", \".png\", \".jpeg\")):\n            if count >= max_images_per_class:\n                break\n            img_path = os.path.join(root, file)\n            img = cv2.imread(img_path)\n            if img is None:\n                continue\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            img = cv2.resize(img, (128,128))\n            # Apply fuzzy entropy preprocessing\n            img = fuzzy_entropy_preprocess(img)\n            img = img.astype(np.float32) / 255.0\n            all_images.append(img)\n            all_labels.append(label_name)\n            count += 1\n    if count > 0:\n        print(f\"Loaded {count} images for label {label_name}\")\n\nX = np.array(all_images)\nlabel_to_idx = {label: idx for idx, label in enumerate(sorted(set(all_labels)))}\ny = np.array([label_to_idx[l] for l in all_labels])\n\nprint(\"Dataset loaded:\", X.shape, y.shape, \"Unique labels:\", np.unique(y))\n\nif X.shape[0] == 0:\n    raise RuntimeError(\"No images loaded. Check dataset structure and image formats.\")\n\n# 2. Build lightweight CNN feature extractor\ndef build_cnn():\n    model = models.Sequential([\n        layers.Conv2D(16, (3,3), activation='relu', input_shape=(128,128,3)),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D(2,2),\n\n        layers.Conv2D(32, (3,3), activation='relu'),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D(2,2),\n\n        layers.Conv2D(64, (3,3), activation='relu'),\n        layers.BatchNormalization(),\n        layers.GlobalAveragePooling2D(),\n\n        layers.Dense(64, activation='relu'),\n        layers.Dropout(0.3),\n        layers.Dense(32, activation='relu')\n    ])\n    return model\n\ncnn_model = build_cnn()\n\n# Extract features in batches to reduce memory usage\nprint(\"Extracting features with CNN...\")\nfeatures = cnn_model.predict(tf.data.Dataset.from_tensor_slices(X).batch(32), verbose=1)\n\n# 3. Ensemble SVM classifier\nsvm1 = SVC(kernel='linear', probability=True)\nsvm2 = SVC(kernel='rbf', probability=True)\nsvm3 = SVC(kernel='poly', degree=3, probability=True)\n\nensemble_svm = VotingClassifier(estimators=[('svm1', svm1), ('svm2', svm2), ('svm3', svm3)], voting='soft')\n\n# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(features, y, test_size=0.2, random_state=42, stratify=y)\n\nensemble_svm.fit(X_train, y_train)\n\n# Predictions\ny_pred = ensemble_svm.predict(X_test)\ny_prob = ensemble_svm.predict_proba(X_test)\n\n# 4. Evaluation\nacc = accuracy_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred, average='macro')\nprecision = precision_score(y_test, y_pred, average='macro')\nf1 = f1_score(y_test, y_pred, average='macro')\nkappa = cohen_kappa_score(y_test, y_pred)\nauc = roc_auc_score(y_test, y_prob, multi_class='ovr')\n\nprint(\"Accuracy:\", acc)\nprint(\"Recall (Sensitivity):\", recall)\nprint(\"Precision:\", precision)\nprint(\"F1 Score:\", f1)\nprint(\"Cohen Kappa:\", kappa)\nprint(\"AUC:\", auc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T14:44:55.777490Z","iopub.execute_input":"2025-09-12T14:44:55.777921Z","iopub.status.idle":"2025-09-12T14:45:44.413949Z","shell.execute_reply.started":"2025-09-12T14:44:55.777894Z","shell.execute_reply":"2025-09-12T14:45:44.413221Z"}},"outputs":[{"name":"stdout","text":"Dataset Path: /kaggle/input/aptos-augmented-images\nLoaded 500 images for label 2\nLoaded 500 images for label 0\nLoaded 500 images for label 3\nLoaded 500 images for label 1\nLoaded 500 images for label 4\nLoaded 500 images for label 2\nLoaded 500 images for label 0\nLoaded 500 images for label 3\nLoaded 500 images for label 1\nLoaded 500 images for label 4\nDataset loaded: (5000, 128, 128, 3) (5000,) Unique labels: [0 1 2 3 4]\nExtracting features with CNN...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\nAccuracy: 0.402\nRecall (Sensitivity): 0.40199999999999997\nPrecision: 0.36004039504423074\nF1 Score: 0.34682958443332057\nCohen Kappa: 0.25249999999999995\nAUC: 0.70919125\n","output_type":"stream"}],"execution_count":3}]}