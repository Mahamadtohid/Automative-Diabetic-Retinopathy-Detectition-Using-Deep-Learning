{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":952963,"sourceType":"datasetVersion","datasetId":505422}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Diabetic Retinopathy Detection - InceptionResNetV2 (Multistage Training)\n\nThis notebook reproduces the pipeline from the paper:\n*Diabetic Retinopathy Detection Using Deep Learning Multistage Training Method* (2025).\n\nDataset: [Diabetic Retinopathy 224x224 (2019 Data)](https://www.kaggle.com/datasets/sovitrath/diabetic-retinopathy-224x224-2019-data)\n\nAuthor: Generated via ChatGPT\n","metadata":{}},{"cell_type":"code","source":"# Install dependencies (Kaggle already has most)\n!pip install -q tensorflow==2.10.0 scikit-image sklearn opencv-python\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T01:23:43.370034Z","iopub.execute_input":"2025-10-03T01:23:43.370381Z","iopub.status.idle":"2025-10-03T01:23:45.069869Z","shell.execute_reply.started":"2025-10-03T01:23:43.370352Z","shell.execute_reply":"2025-10-03T01:23:45.068905Z"}},"outputs":[{"name":"stdout","text":"\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.10.0 (from versions: 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1, 2.14.0rc0, 2.14.0rc1, 2.14.0, 2.14.1, 2.15.0rc0, 2.15.0rc1, 2.15.0, 2.15.0.post1, 2.15.1, 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0, 2.17.1, 2.18.0rc0, 2.18.0rc1, 2.18.0rc2, 2.18.0, 2.18.1, 2.19.0rc0, 2.19.0, 2.19.1, 2.20.0rc0, 2.20.0)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.10.0\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"import os, glob, shutil, hashlib\nimport numpy as np, pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, optimizers\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nimport cv2\nfrom skimage.transform import warp_polar\n\nTARGET_SIZE = (224,224)\nNUM_CLASSES = 5\nDATASET_ROOT = \"/kaggle/input/diabetic-retinopathy-224x224-2019-data\"\nSTANDARD_ROOT = os.path.join(DATASET_ROOT, 'colored_images')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T01:23:45.071568Z","iopub.execute_input":"2025-10-03T01:23:45.071849Z","iopub.status.idle":"2025-10-03T01:23:45.077189Z","shell.execute_reply.started":"2025-10-03T01:23:45.071824Z","shell.execute_reply":"2025-10-03T01:23:45.076492Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# Preprocessing helpers\ndef load_image(path):\n    img = cv2.imread(path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    return img\n\ndef autocrop_black(img, tol=7):\n    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n    mask = gray > tol\n    if mask.any():\n        coords = np.argwhere(mask)\n        y0,x0 = coords.min(axis=0)\n        y1,x1 = coords.max(axis=0)\n        return img[y0:y1+1, x0:x1+1]\n    return img\n\ndef circular_crop(img):\n    h,w = img.shape[:2]\n    center = (w//2,h//2)\n    radius = min(center[0],center[1],w-center[0],h-center[1])\n    Y,X = np.ogrid[:h,:w]\n    mask = (X-center[0])**2+(Y-center[1])**2 <= radius**2\n    out = img.copy()\n    out[~mask] = 0\n    return out\n\ndef preprocess_image_file(path):\n    img = load_image(path)\n    img = autocrop_black(img)\n    img = circular_crop(img)\n    img = cv2.resize(img, TARGET_SIZE)\n    return img\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T01:23:45.077982Z","iopub.execute_input":"2025-10-03T01:23:45.078710Z","iopub.status.idle":"2025-10-03T01:23:45.098002Z","shell.execute_reply.started":"2025-10-03T01:23:45.078687Z","shell.execute_reply":"2025-10-03T01:23:45.097391Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"class_map = {\n    \"No DR\": 0,\n    \"Mild\": 1,\n    \"Moderate\": 2,\n    \"Severe\": 3,\n    \"Proliferative DR\": 4\n}\n\ndef make_file_list_and_labels(root_dir):\n    classes = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir,d))]\n    files, labels = [], []\n    for c in classes:\n        c_clean = c.strip()  # remove leading/trailing spaces\n        if c_clean not in class_map:\n            print(f\"Skipping unknown folder: '{c}'\")  # debug\n            continue\n        class_label = class_map[c_clean]\n        for p in glob.glob(os.path.join(root_dir, c, '*')):\n            files.append(p)\n            labels.append(class_label)\n    return files, labels, classes\n\nfiles, labels, classes = make_file_list_and_labels(STANDARD_ROOT)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T01:28:21.699283Z","iopub.execute_input":"2025-10-03T01:28:21.699594Z","iopub.status.idle":"2025-10-03T01:28:21.728067Z","shell.execute_reply.started":"2025-10-03T01:28:21.699574Z","shell.execute_reply":"2025-10-03T01:28:21.727496Z"}},"outputs":[{"name":"stdout","text":"Skipping unknown folder: 'Proliferate_DR'\nSkipping unknown folder: 'No_DR'\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_temp, y_train, y_temp = train_test_split(files, labels, test_size=0.2, stratify=labels, random_state=42)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T01:28:37.768998Z","iopub.execute_input":"2025-10-03T01:28:37.769244Z","iopub.status.idle":"2025-10-03T01:28:37.796514Z","shell.execute_reply.started":"2025-10-03T01:28:37.769227Z","shell.execute_reply":"2025-10-03T01:28:37.795883Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"AUTOTUNE = tf.data.AUTOTUNE\ndef path_label_to_dataset(paths, labels, batch_size=32, shuffle=True):\n    paths = tf.constant(paths)\n    labels = tf.constant(labels)\n    ds = tf.data.Dataset.from_tensor_slices((paths,labels))\n    if shuffle:\n        ds = ds.shuffle(len(paths))\n    def _load(path,label):\n        img = tf.numpy_function(lambda p: preprocess_image_file(p.decode()), [path], tf.uint8)\n        img = tf.cast(img, tf.float32)/255.0\n        return img,label\n    ds = ds.map(_load,num_parallel_calls=AUTOTUNE).batch(batch_size).prefetch(AUTOTUNE)\n    return ds\n\ntrain_ds = path_label_to_dataset(X_train,y_train)\nval_ds = path_label_to_dataset(X_val,y_val)\ntest_ds = path_label_to_dataset(X_test,y_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T01:28:42.709298Z","iopub.execute_input":"2025-10-03T01:28:42.710009Z","iopub.status.idle":"2025-10-03T01:28:42.762402Z","shell.execute_reply.started":"2025-10-03T01:28:42.709986Z","shell.execute_reply":"2025-10-03T01:28:42.761866Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"# Build InceptionResNetV2 with custom head\nbase_model = tf.keras.applications.InceptionResNetV2(include_top=False,weights='imagenet',input_shape=(224,224,3))\nx = base_model.output\nx = layers.AveragePooling2D(pool_size=(5,5))(x)\nx = layers.Flatten()(x)\nx = layers.Dropout(0.2)(x)\nx = layers.BatchNormalization()(x)\nout = layers.Dense(NUM_CLASSES,activation='softmax')(x)\nmodel = models.Model(inputs=base_model.input,outputs=out)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T01:28:47.210034Z","iopub.execute_input":"2025-10-03T01:28:47.210594Z","iopub.status.idle":"2025-10-03T01:28:54.546374Z","shell.execute_reply.started":"2025-10-03T01:28:47.210571Z","shell.execute_reply":"2025-10-03T01:28:54.545816Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m219055592/219055592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"import tensorflow as tf\n\nBATCH_SIZE = 32\nIMG_SIZE = (224, 224)\n\ntrain_ds = tf.keras.utils.image_dataset_from_directory(\n    STANDARD_ROOT,\n    validation_split=0.2,\n    subset=\"training\",\n    seed=42,\n    image_size=IMG_SIZE,\n    batch_size=BATCH_SIZE\n)\n\nval_ds = tf.keras.utils.image_dataset_from_directory(\n    STANDARD_ROOT,\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=42,\n    image_size=IMG_SIZE,\n    batch_size=BATCH_SIZE\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T01:30:28.593898Z","iopub.execute_input":"2025-10-03T01:30:28.594584Z","iopub.status.idle":"2025-10-03T01:30:36.649790Z","shell.execute_reply.started":"2025-10-03T01:30:28.594558Z","shell.execute_reply":"2025-10-03T01:30:36.648923Z"}},"outputs":[{"name":"stdout","text":"Found 3662 files belonging to 5 classes.\nUsing 2930 files for training.\nFound 3662 files belonging to 5 classes.\nUsing 732 files for validation.\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"# Stage 1: freeze base\nfor l in base_model.layers:\n    l.trainable = False\nmodel.compile(optimizer=optimizers.Adam(1e-3),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\nhistory1 = model.fit(train_ds,validation_data=val_ds,epochs=25)\n\n# Stage 2: fine-tune from layer 100\nfor i,l in enumerate(base_model.layers):\n    if i>=100: l.trainable=True\nmodel.compile(optimizer=optimizers.Adam(1e-5),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\nhistory2 = model.fit(train_ds,validation_data=val_ds,epochs=25)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T01:31:21.454885Z","iopub.execute_input":"2025-10-03T01:31:21.455674Z","iopub.status.idle":"2025-10-03T01:52:17.910921Z","shell.execute_reply.started":"2025-10-03T01:31:21.455648Z","shell.execute_reply":"2025-10-03T01:52:17.910092Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/25\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1759455107.616961     109 service.cc:148] XLA service 0x7f0aa0004540 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1759455107.617766     109 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1759455112.251310     109 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 1/92\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m58:25\u001b[0m 39s/step - accuracy: 0.1875 - loss: 2.0593","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1759455119.886309     109 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 448ms/step - accuracy: 0.3813 - loss: 1.7068 - val_accuracy: 0.6066 - val_loss: 1.1861\nEpoch 2/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - accuracy: 0.5862 - loss: 1.2146 - val_accuracy: 0.6612 - val_loss: 0.9629\nEpoch 3/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - accuracy: 0.6150 - loss: 1.1383 - val_accuracy: 0.6626 - val_loss: 0.9540\nEpoch 4/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - accuracy: 0.6045 - loss: 1.1409 - val_accuracy: 0.6694 - val_loss: 0.9215\nEpoch 5/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - accuracy: 0.6184 - loss: 1.0824 - val_accuracy: 0.6639 - val_loss: 0.9234\nEpoch 6/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - accuracy: 0.6273 - loss: 1.0749 - val_accuracy: 0.6803 - val_loss: 0.9077\nEpoch 7/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - accuracy: 0.6225 - loss: 1.0493 - val_accuracy: 0.6776 - val_loss: 0.8760\nEpoch 8/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - accuracy: 0.6234 - loss: 1.0587 - val_accuracy: 0.6790 - val_loss: 0.8887\nEpoch 9/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - accuracy: 0.6338 - loss: 1.0554 - val_accuracy: 0.6885 - val_loss: 0.8806\nEpoch 10/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - accuracy: 0.6242 - loss: 1.0347 - val_accuracy: 0.6844 - val_loss: 0.8900\nEpoch 11/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - accuracy: 0.6195 - loss: 1.0429 - val_accuracy: 0.6817 - val_loss: 0.8754\nEpoch 12/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - accuracy: 0.6457 - loss: 0.9725 - val_accuracy: 0.6899 - val_loss: 0.8796\nEpoch 13/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - accuracy: 0.6420 - loss: 1.0089 - val_accuracy: 0.6790 - val_loss: 0.9218\nEpoch 14/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - accuracy: 0.6525 - loss: 0.9668 - val_accuracy: 0.6858 - val_loss: 0.8768\nEpoch 15/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - accuracy: 0.6437 - loss: 0.9985 - val_accuracy: 0.6926 - val_loss: 0.8680\nEpoch 16/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - accuracy: 0.6264 - loss: 1.0082 - val_accuracy: 0.6844 - val_loss: 0.8938\nEpoch 17/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - accuracy: 0.6371 - loss: 1.0059 - val_accuracy: 0.6680 - val_loss: 0.9284\nEpoch 18/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - accuracy: 0.6291 - loss: 1.0042 - val_accuracy: 0.6817 - val_loss: 0.8837\nEpoch 19/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - accuracy: 0.6417 - loss: 1.0061 - val_accuracy: 0.6885 - val_loss: 0.8704\nEpoch 20/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - accuracy: 0.6605 - loss: 0.9695 - val_accuracy: 0.6926 - val_loss: 0.8643\nEpoch 21/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - accuracy: 0.6314 - loss: 0.9952 - val_accuracy: 0.6872 - val_loss: 0.8869\nEpoch 22/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - accuracy: 0.6533 - loss: 0.9674 - val_accuracy: 0.6858 - val_loss: 0.9018\nEpoch 23/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - accuracy: 0.6564 - loss: 0.9744 - val_accuracy: 0.6858 - val_loss: 0.8894\nEpoch 24/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - accuracy: 0.6432 - loss: 0.9764 - val_accuracy: 0.6967 - val_loss: 0.8742\nEpoch 25/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - accuracy: 0.6510 - loss: 0.9518 - val_accuracy: 0.6940 - val_loss: 0.8715\nEpoch 1/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 1s/step - accuracy: 0.5131 - loss: 1.2539 - val_accuracy: 0.1749 - val_loss: 2.1126\nEpoch 2/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 300ms/step - accuracy: 0.6870 - loss: 0.8929 - val_accuracy: 0.6270 - val_loss: 1.1432\nEpoch 3/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 300ms/step - accuracy: 0.7058 - loss: 0.8251 - val_accuracy: 0.7104 - val_loss: 0.9254\nEpoch 4/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 300ms/step - accuracy: 0.7278 - loss: 0.7848 - val_accuracy: 0.7227 - val_loss: 0.8538\nEpoch 5/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 300ms/step - accuracy: 0.7407 - loss: 0.7507 - val_accuracy: 0.7213 - val_loss: 0.7809\nEpoch 6/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 301ms/step - accuracy: 0.7342 - loss: 0.7349 - val_accuracy: 0.7268 - val_loss: 0.7540\nEpoch 7/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 300ms/step - accuracy: 0.7518 - loss: 0.7069 - val_accuracy: 0.7336 - val_loss: 0.7196\nEpoch 8/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 300ms/step - accuracy: 0.7514 - loss: 0.7000 - val_accuracy: 0.7363 - val_loss: 0.7081\nEpoch 9/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 299ms/step - accuracy: 0.7450 - loss: 0.7073 - val_accuracy: 0.7377 - val_loss: 0.7119\nEpoch 10/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 300ms/step - accuracy: 0.7721 - loss: 0.6390 - val_accuracy: 0.7445 - val_loss: 0.7008\nEpoch 11/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 300ms/step - accuracy: 0.7710 - loss: 0.6272 - val_accuracy: 0.7473 - val_loss: 0.7110\nEpoch 12/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 300ms/step - accuracy: 0.7876 - loss: 0.6081 - val_accuracy: 0.7445 - val_loss: 0.6992\nEpoch 13/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 299ms/step - accuracy: 0.7807 - loss: 0.5907 - val_accuracy: 0.7377 - val_loss: 0.7083\nEpoch 14/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 301ms/step - accuracy: 0.7894 - loss: 0.5520 - val_accuracy: 0.7432 - val_loss: 0.7135\nEpoch 15/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 300ms/step - accuracy: 0.7950 - loss: 0.5545 - val_accuracy: 0.7514 - val_loss: 0.7184\nEpoch 16/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 301ms/step - accuracy: 0.8048 - loss: 0.5247 - val_accuracy: 0.7268 - val_loss: 0.7889\nEpoch 17/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 301ms/step - accuracy: 0.8078 - loss: 0.5111 - val_accuracy: 0.7445 - val_loss: 0.7213\nEpoch 18/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 301ms/step - accuracy: 0.8301 - loss: 0.4672 - val_accuracy: 0.7568 - val_loss: 0.7075\nEpoch 19/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 300ms/step - accuracy: 0.8348 - loss: 0.4427 - val_accuracy: 0.7391 - val_loss: 0.8389\nEpoch 20/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 300ms/step - accuracy: 0.8523 - loss: 0.4236 - val_accuracy: 0.7664 - val_loss: 0.7408\nEpoch 21/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 300ms/step - accuracy: 0.8575 - loss: 0.3882 - val_accuracy: 0.7295 - val_loss: 0.8264\nEpoch 22/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 300ms/step - accuracy: 0.8596 - loss: 0.3705 - val_accuracy: 0.7500 - val_loss: 0.8432\nEpoch 23/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 300ms/step - accuracy: 0.8733 - loss: 0.3465 - val_accuracy: 0.7363 - val_loss: 0.9284\nEpoch 24/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 300ms/step - accuracy: 0.8855 - loss: 0.3125 - val_accuracy: 0.7104 - val_loss: 0.9864\nEpoch 25/25\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 300ms/step - accuracy: 0.8934 - loss: 0.2978 - val_accuracy: 0.7445 - val_loss: 0.8426\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"test_ds = tf.keras.utils.image_dataset_from_directory(\n    STANDARD_ROOT,\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=42,\n    image_size=(224,224),\n    batch_size=32\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T02:01:50.456376Z","iopub.execute_input":"2025-10-03T02:01:50.456717Z","iopub.status.idle":"2025-10-03T02:01:51.377863Z","shell.execute_reply.started":"2025-10-03T02:01:50.456694Z","shell.execute_reply":"2025-10-03T02:01:51.377008Z"}},"outputs":[{"name":"stdout","text":"Found 3662 files belonging to 5 classes.\nUsing 732 files for validation.\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"# Evaluate\nprint(model.evaluate(test_ds))\ny_true,y_pred=[],[]\nfor x,y in test_ds:\n    p = np.argmax(model.predict(x),axis=1)\n    y_true.extend(y.numpy().tolist())\n    y_pred.extend(p.tolist())\nprint(classification_report(y_true,y_pred))\n#model.save(\"inceptionresnetv2_dr_multistage.h5\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T02:01:54.286925Z","iopub.execute_input":"2025-10-03T02:01:54.287215Z","iopub.status.idle":"2025-10-03T02:02:28.427563Z","shell.execute_reply.started":"2025-10-03T02:01:54.287181Z","shell.execute_reply":"2025-10-03T02:02:28.426650Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.7412 - loss: 0.8407\n[0.8426254987716675, 0.744535505771637]\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step\n              precision    recall  f1-score   support\n\n           0       0.34      0.58      0.43        59\n           1       0.67      0.66      0.67       205\n           2       0.94      0.96      0.95       363\n           3       0.37      0.24      0.29        59\n           4       0.57      0.26      0.36        46\n\n    accuracy                           0.74       732\n   macro avg       0.58      0.54      0.54       732\nweighted avg       0.75      0.74      0.74       732\n\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}